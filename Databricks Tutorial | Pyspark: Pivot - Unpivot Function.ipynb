{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b2186c3-fb3a-4a91-8ce8-bdc39ba2ad9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83fee9ea-4881-4108-a0b1-df5f2c496b1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data = [\n",
    "    (\"Alice\", \"East\", \"Jan\", 100),\n",
    "    (\"Alice\", \"East\", \"Feb\", 120),\n",
    "    (\"Alice\", \"East\", \"Mar\", 130),\n",
    "    (\"Bob\", \"West\", \"Jan\", 90),\n",
    "    (\"Bob\", \"West\", \"Feb\", 110)\n",
    "]\n",
    "\n",
    "# Define Schema\n",
    "schema = StructType([StructField(\"name\", StringType()),\n",
    "                     StructField(\"region\", StringType()),\n",
    "                     StructField(\"month\", StringType()),\n",
    "                     StructField(\"sales\", FloatType())])\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c165dcdc-0875-4a7f-a922-2649febbfecc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pivot table\n",
    "df_pivot = df.groupBy(\"name\", \"region\").pivot(\"month\").sum(\"sales\")\n",
    "display(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1b2c530-bc03-42aa-a150-48471a516967",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Unpivot table\n",
    "unpivotExpr = \"stack(3, 'Feb', Feb, 'Jan', Jan, 'Mar', Mar)\"\n",
    "df_unpivot = df_pivot.select(\"name\",\"region\", expr(unpivotExpr).alias(\"month\",\"sales\"))\n",
    "\n",
    "display(df_unpivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "849e6d7d-2570-4972-a1c6-9eef64447e5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks Tutorial | Pyspark: Pivot - Unpivot Function",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
